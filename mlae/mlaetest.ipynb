{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use EXP-4 100 rows for testing mlae "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "balanced_df = pd.read_csv('balanced_data_sample.csv')\n",
    "#balanced_df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Daniel, I found something interesing here\n",
    "\n",
    "From your code: [run_position_angle.py](https://github.com/haehn/perception/blob/master/EXP/run_position_angle.py),  \n",
    "\n",
    "I found you are using this calculation:  \n",
    "\n",
    "```python\n",
    "MLAE = np.log2(sklearn.metrics.mean_absolute_error(y_pred * 100, y_test * 100) + 0.125)\n",
    "```\n",
    "\n",
    "And I think this is the correct calculation for **Cleveland and McGrill**.  \n",
    "\n",
    "However, at the beginning, you can check this link:  \n",
    "[LLMP/evaluator.py](https://github.com/kenichi-maeda/LLMP/blob/main/LLMP/evaluator.py)  \n",
    "\n",
    "I originally used this MLAE calculation for our project:  \n",
    "\n",
    "```python\n",
    "mlae = np.log2(mean_absolute_error(gt_array, answers_array) + 0.125)\n",
    "```\n",
    "\n",
    "My Thought:  \n",
    "I think I **did not** use Cleveland and McGrill's MLAE calculation for our project.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example Calculation for Model: CustomLLaMA\n",
      "Ground Truth: [6 8 9 8 8]\n",
      "Predictions: [ 9. 10.  3.  3. 10.]\n",
      "Step-by-Step Cleveland-McGill MLAE Calculation:\n",
      "Mean Absolute Error (MAE) * 100: 36000.0000\n",
      "MLAE = log2(36000.0000 + 0.125) = 8.4924\n",
      "\n",
      "Step-by-Step Per-Instance MLAE Calculation:\n",
      "Instance 1: GT = 6, Pred = 9.0, MLAE = log2(|6 - 9.0| + 0.125) = 1.6439\n",
      "Instance 2: GT = 8, Pred = 10.0, MLAE = log2(|8 - 10.0| + 0.125) = 1.0875\n",
      "Instance 3: GT = 9, Pred = 3.0, MLAE = log2(|9 - 3.0| + 0.125) = 2.6147\n",
      "Instance 4: GT = 8, Pred = 3.0, MLAE = log2(|8 - 3.0| + 0.125) = 2.3576\n",
      "Instance 5: GT = 8, Pred = 10.0, MLAE = log2(|8 - 10.0| + 0.125) = 1.0875\n",
      "Average Per-Instance MLAE: 1.7582\n",
      "\n",
      "Example Calculation for Model: Gemini1_5Flash\n",
      "Ground Truth: [6 8 9 3 8]\n",
      "Predictions: [7. 7. 7. 7. 7.]\n",
      "Step-by-Step Cleveland-McGill MLAE Calculation:\n",
      "Mean Absolute Error (MAE) * 100: 18000.0000\n",
      "MLAE = log2(18000.0000 + 0.125) = 7.4929\n",
      "\n",
      "Step-by-Step Per-Instance MLAE Calculation:\n",
      "Instance 1: GT = 6, Pred = 7.0, MLAE = log2(|6 - 7.0| + 0.125) = 0.1699\n",
      "Instance 2: GT = 8, Pred = 7.0, MLAE = log2(|8 - 7.0| + 0.125) = 0.1699\n",
      "Instance 3: GT = 9, Pred = 7.0, MLAE = log2(|9 - 7.0| + 0.125) = 1.0875\n",
      "Instance 4: GT = 3, Pred = 7.0, MLAE = log2(|3 - 7.0| + 0.125) = 2.0444\n",
      "Instance 5: GT = 8, Pred = 7.0, MLAE = log2(|8 - 7.0| + 0.125) = 0.1699\n",
      "Average Per-Instance MLAE: 0.7283\n",
      "\n",
      "Example Calculation for Model: GeminiProVision\n",
      "Ground Truth: [ 6  3 10  1 10]\n",
      "Predictions: [7. 7. 7. 7. 7.]\n",
      "Step-by-Step Cleveland-McGill MLAE Calculation:\n",
      "Mean Absolute Error (MAE) * 100: 34000.0000\n",
      "MLAE = log2(34000.0000 + 0.125) = 8.4099\n",
      "\n",
      "Step-by-Step Per-Instance MLAE Calculation:\n",
      "Instance 1: GT = 6, Pred = 7.0, MLAE = log2(|6 - 7.0| + 0.125) = 0.1699\n",
      "Instance 2: GT = 3, Pred = 7.0, MLAE = log2(|3 - 7.0| + 0.125) = 2.0444\n",
      "Instance 3: GT = 10, Pred = 7.0, MLAE = log2(|10 - 7.0| + 0.125) = 1.6439\n",
      "Instance 4: GT = 1, Pred = 7.0, MLAE = log2(|1 - 7.0| + 0.125) = 2.6147\n",
      "Instance 5: GT = 10, Pred = 7.0, MLAE = log2(|10 - 7.0| + 0.125) = 1.6439\n",
      "Average Per-Instance MLAE: 1.6233\n",
      "\n",
      "Example Calculation for Model: LLaMA\n",
      "Ground Truth: [ 1  5  1 10  6]\n",
      "Predictions: [ 4.  5.  5.  3. 10.]\n",
      "Step-by-Step Cleveland-McGill MLAE Calculation:\n",
      "Mean Absolute Error (MAE) * 100: 36000.0000\n",
      "MLAE = log2(36000.0000 + 0.125) = 8.4924\n",
      "\n",
      "Step-by-Step Per-Instance MLAE Calculation:\n",
      "Instance 1: GT = 1, Pred = 4.0, MLAE = log2(|1 - 4.0| + 0.125) = 1.6439\n",
      "Instance 2: GT = 5, Pred = 5.0, MLAE = log2(|5 - 5.0| + 0.125) = -3.0000\n",
      "Instance 3: GT = 1, Pred = 5.0, MLAE = log2(|1 - 5.0| + 0.125) = 2.0444\n",
      "Instance 4: GT = 10, Pred = 3.0, MLAE = log2(|10 - 3.0| + 0.125) = 2.8329\n",
      "Instance 5: GT = 6, Pred = 10.0, MLAE = log2(|6 - 10.0| + 0.125) = 2.0444\n",
      "Average Per-Instance MLAE: 1.1131\n",
      "\n",
      "Example Calculation for Model: gpt4o\n",
      "Ground Truth: [ 7 10  9  9  6]\n",
      "Predictions: [ 9. 10. 10. 10.  5.]\n",
      "Step-by-Step Cleveland-McGill MLAE Calculation:\n",
      "Mean Absolute Error (MAE) * 100: 10000.0000\n",
      "MLAE = log2(10000.0000 + 0.125) = 6.6457\n",
      "\n",
      "Step-by-Step Per-Instance MLAE Calculation:\n",
      "Instance 1: GT = 7, Pred = 9.0, MLAE = log2(|7 - 9.0| + 0.125) = 1.0875\n",
      "Instance 2: GT = 10, Pred = 10.0, MLAE = log2(|10 - 10.0| + 0.125) = -3.0000\n",
      "Instance 3: GT = 9, Pred = 10.0, MLAE = log2(|9 - 10.0| + 0.125) = 0.1699\n",
      "Instance 4: GT = 9, Pred = 10.0, MLAE = log2(|9 - 10.0| + 0.125) = 0.1699\n",
      "Instance 5: GT = 6, Pred = 5.0, MLAE = log2(|6 - 5.0| + 0.125) = 0.1699\n",
      "Average Per-Instance MLAE: -0.2806\n",
      "\n",
      "MLAE Comparison (Cleveland-McGill vs. Per-Instance MLAE):\n",
      "CustomLLaMA: Cleveland-McGill MLAE = 8.0851, Per-Instance MLAE = 1.0086\n",
      "Gemini1_5Flash: Cleveland-McGill MLAE = 7.6100, Per-Instance MLAE = 0.5031\n",
      "GeminiProVision: Cleveland-McGill MLAE = 8.0920, Per-Instance MLAE = 1.3018\n",
      "LLaMA: Cleveland-McGill MLAE = 8.2074, Per-Instance MLAE = 1.1650\n",
      "gpt4o: Cleveland-McGill MLAE = 8.0231, Per-Instance MLAE = 0.9103\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "# MLAE Calculation 1: Cleveland-McGill (Log Transformed MAE)\n",
    "def Cleveland_McGill(y_pred, y_test):\n",
    "    return np.log2(metrics.mean_absolute_error(y_pred * 100, y_test * 100) + 0.125)\n",
    "\n",
    "# MLAE Calculation 2: Per-Instance Log Transformed MAE\n",
    "def MLAE_per_instance(y_pred, y_test):\n",
    "    mlae_values = [\n",
    "        np.log2(metrics.mean_absolute_error([gt], [pred]) + 0.125) \n",
    "        for gt, pred in zip(y_test, y_pred)\n",
    "    ]\n",
    "    return np.mean(mlae_values)  # Average across all instances\n",
    "\n",
    "# Load dataset\n",
    "df = balanced_df.copy()\n",
    "\n",
    "# Convert columns to numeric\n",
    "df['ground_truth'] = pd.to_numeric(df['ground_truth'], errors='coerce')\n",
    "df['cleaned_answers'] = pd.to_numeric(df['cleaned_answers'], errors='coerce')\n",
    "\n",
    "# Drop missing values\n",
    "df = df.dropna(subset=['ground_truth', 'cleaned_answers'])\n",
    "\n",
    "# Compute MLAE for each model\n",
    "mlae_results = {}\n",
    "for model, group in df.groupby('model_name'):\n",
    "    y_test = group['ground_truth'].values\n",
    "    y_pred = group['cleaned_answers'].values\n",
    "\n",
    "    mlae_Cleveland_McGill = Cleveland_McGill(y_pred, y_test)\n",
    "    mlae_per_instance = MLAE_per_instance(y_pred, y_test)\n",
    "\n",
    "    mlae_results[model] = (mlae_Cleveland_McGill, mlae_per_instance)\n",
    "\n",
    "    # Display Example Calculation for First 5 Rows\n",
    "    print(f\"\\nExample Calculation for Model: {model}\")\n",
    "\n",
    "    # Take the first 5 rows for demonstration\n",
    "    example_y_test = y_test[:5]\n",
    "    example_y_pred = y_pred[:5]\n",
    "\n",
    "    print(f\"Ground Truth: {example_y_test}\")\n",
    "    print(f\"Predictions: {example_y_pred}\")\n",
    "\n",
    "    # Step-by-step for Cleveland-McGill MLAE\n",
    "    example_mae = metrics.mean_absolute_error(example_y_pred * 100, example_y_test * 100)\n",
    "    log_mae = np.log2(example_mae + 0.125)\n",
    "\n",
    "    print(f\"Step-by-Step Cleveland-McGill MLAE Calculation:\")\n",
    "    print(f\"Mean Absolute Error (MAE) * 100: {example_mae * 100:.4f}\")\n",
    "    print(f\"MLAE = log2({example_mae * 100:.4f} + 0.125) = {log_mae:.4f}\")\n",
    "\n",
    "    # Step-by-step for Per-Instance MLAE\n",
    "    per_instance_values = [\n",
    "        np.log2(metrics.mean_absolute_error([gt], [pred]) + 0.125) \n",
    "        for gt, pred in zip(example_y_test, example_y_pred)\n",
    "    ]\n",
    "\n",
    "    print(f\"\\nStep-by-Step Per-Instance MLAE Calculation:\")\n",
    "    for i, (gt, pred, per_mlae) in enumerate(zip(example_y_test, example_y_pred, per_instance_values)):\n",
    "        print(f\"Instance {i+1}: GT = {gt}, Pred = {pred}, MLAE = log2(|{gt} - {pred}| + 0.125) = {per_mlae:.4f}\")\n",
    "\n",
    "    print(f\"Average Per-Instance MLAE: {np.mean(per_instance_values):.4f}\")\n",
    "\n",
    "# Display final results for all models\n",
    "print(\"\\nMLAE Comparison (Cleveland-McGill vs. Per-Instance MLAE):\")\n",
    "for model, (mlae_Cleveland_McGill, mlae_per_instance) in mlae_results.items():\n",
    "    print(f\"{model}: Cleveland-McGill MLAE = {mlae_Cleveland_McGill:.4f}, Per-Instance MLAE = {mlae_per_instance:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continue to understand why? https://chatgpt.com/c/67a0bc52-4948-800b-b745-465bb11f566f "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sbatch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
