{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use EXP-4 100 rows for testing mlae "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2472 entries, 0 to 2471\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   task_name        2472 non-null   int64  \n",
      " 1   query            2472 non-null   object \n",
      " 2   run              2472 non-null   int64  \n",
      " 3   model_name       2472 non-null   object \n",
      " 4   image_path       2472 non-null   object \n",
      " 5   ground_truth     2472 non-null   int64  \n",
      " 6   raw_answer       2472 non-null   object \n",
      " 7   time_ms          2472 non-null   float64\n",
      " 8   parsed_answers   2472 non-null   float64\n",
      " 9   cleaned_answers  2472 non-null   float64\n",
      "dtypes: float64(3), int64(3), object(4)\n",
      "memory usage: 193.2+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "balanced_df = pd.read_csv('balanceddata.csv')\n",
    "\n",
    "balanced_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I would like to know how mlae is being caculated for each model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MLAE Comparison (Cleveland-McGill vs. Per-Instance MLAE):\n",
      "CustomLLaMA: Cleveland-McGill MLAE = 8.3361, Per-Instance MLAE = 1.1383\n",
      "Gemini1_5Flash: Cleveland-McGill MLAE = 7.9064, Per-Instance MLAE = 0.7923\n",
      "GeminiProVision: Cleveland-McGill MLAE = 8.0186, Per-Instance MLAE = 0.8843\n",
      "LLaMA: Cleveland-McGill MLAE = 9.1475, Per-Instance MLAE = 1.1656\n",
      "gpt4o: Cleveland-McGill MLAE = 8.0533, Per-Instance MLAE = 0.8373\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "# MLAE Calculation 1: Cleveland-McGill (Log Transformed MAE)\n",
    "def Cleveland_McGill(y_pred, y_test):\n",
    "    return np.log2(metrics.mean_absolute_error(y_pred * 100, y_test * 100) + 0.125)\n",
    "\n",
    "# MLAE Calculation 2: Per-Instance Log Transformed MAE\n",
    "def MLAE_per_instance(y_pred, y_test):\n",
    "    mlae_values = [\n",
    "        np.log2(metrics.mean_absolute_error([gt], [pred]) + 0.125) \n",
    "        for gt, pred in zip(y_test, y_pred)\n",
    "    ]\n",
    "    return np.mean(mlae_values)  # Average across all instances\n",
    "\n",
    "# Load dataset\n",
    "df = balanced_df.copy()\n",
    "\n",
    "# Compute MLAE for each model\n",
    "mlae_results = {}\n",
    "\n",
    "for model, group in df.groupby('model_name'):\n",
    "    y_test = group['ground_truth'].values\n",
    "    y_pred = group['cleaned_answers'].values\n",
    "\n",
    "    mlae_results[model] = (\n",
    "        Cleveland_McGill(y_pred, y_test),\n",
    "        MLAE_per_instance(y_pred, y_test)\n",
    "    )\n",
    "\n",
    "# Display final MLAE comparison\n",
    "print(\"\\nMLAE Comparison (Cleveland-McGill vs. Per-Instance MLAE):\")\n",
    "for model, (mlae_Cleveland_McGill, mlae_per_instance) in mlae_results.items():\n",
    "    print(f\"{model}: Cleveland-McGill MLAE = {mlae_Cleveland_McGill:.4f}, Per-Instance MLAE = {mlae_per_instance:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My question right now is which one is reasonable for this case?\n",
    "\n",
    "for finetuned models are okay to use per-instance MLAE caculation, as their predictions are small integers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique Predicted Values for CustomLLaMA:\n",
      "[ 9. 10.  3.  2.  7.  4.  1.  6.  5.  8.]\n",
      "\n",
      "Unique Predicted Values for Gemini1_5Flash:\n",
      "[7. 6. 8.]\n",
      "\n",
      "Unique Predicted Values for GeminiProVision:\n",
      "[7. 2. 4.]\n",
      "\n",
      "Unique Predicted Values for LLaMA:\n",
      "[  4.   5.   3.  10.   6.  15.   7. 100.   2.   8.   9.  20.  52.  36.\n",
      "  50.   1. 145.  35.  40.  30.  13. 140.  24. 152.  55.  90.  45. 300.\n",
      "  16.]\n",
      "\n",
      "Unique Predicted Values for gpt4o:\n",
      "[ 9. 10.  5.  7.  3.  8.  6.  4.  2.]\n"
     ]
    }
   ],
   "source": [
    "# Get unique predicted values for each model\n",
    "unique_predictions_per_model = {}\n",
    "\n",
    "for model, group in df.groupby('model_name'):\n",
    "    unique_predictions_per_model[model] = group['cleaned_answers'].unique()\n",
    "\n",
    "# Display unique values for each model\n",
    "for model, unique_values in unique_predictions_per_model.items():\n",
    "    print(f\"\\nUnique Predicted Values for {model}:\")\n",
    "    print(unique_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I see unique predicted value for llama model: they have larger value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caculate gpt-4o's mlae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Predicted Values for GPT-4o:\n",
      "[ 9. 10.  5.  7.  3.  8.  6.  4.  2.]\n",
      "\n",
      "Example MLAE Calculation for GPT-4o (First 5 Rows):\n",
      "Ground Truth: [ 7 10  9  9  6  3  2  1  2  8  1  5  1  9  4  3  7 10  3  9  6  4  8  6\n",
      "  2  8  9 10  8  1  8  5  9  3  7  7  7  7  8  6  3  5  7  2  5  7  4  3\n",
      "  8 10  1  5  7  9  6  9  8  9  3  8  1 10 10  2 10  6  5  5  5  4  5  8\n",
      "  2  5  2  3  1  1  6 10  6  9  4  7  9 10  8  8  6  8  7 10  5  3 10  6\n",
      "  6  5  7  6  2  6 10 10  6 10  8  4 10  5  3  4  9  6 10  9  4  8  5  3\n",
      "  4  7  7  8  2  4  8  9  4  9  3  6  5  7  3  3  3  8  8  5  7  3  3  7\n",
      "  3  5  9  4 10  7  8  6  3  4  9  9 10  6  4  5  8  3  3  1  4  2  1  1\n",
      "  7  6  6  9  9  8  3  1  9 10  2  4  1  4  3  1  4  7  7  2  3  1  8  8\n",
      "  1  7  5  8  5 10  8  6  9  8  7 10  1  6  6  6  4  9  4  8  1  7  1  8\n",
      "  1  9  7  8  8  6  7  8  3  4  6  9  7  6  7  4  3  3  7  8  3  7  6  3\n",
      "  2  1  8  6  1  9  3  3  9  1  5  9  2  6  6  4  8  7  6  2  8  1  2  4\n",
      "  1 10  1  6  9  8  8  2  9  5  3  1  6  9  6  6  3  9  8  3 10 10  9  4\n",
      "  8  9  6  8  8  6  6  4  6  9  1  4 10  5  7  3  3  4  5  7  1  4  7  4\n",
      "  6  9 10  3  2  4 10  7  1  3  6  7  4  4  3  8  8  3  5  6  8  4 10  6\n",
      "  6  5  3  1  4  1  8  5  4  7  9  7  6  5  8  5 10 10  8  7  5  6  8  8\n",
      "  1  7 10 10  3  4  5  1  7 10  3  8  9  2  6  4  6  3  8  3  7  6  6  8\n",
      "  3  6 10  3  8  7  5  5 10  4  6  1  6  6  8  5 10  1  4  9  8  3  4  8\n",
      "  9  5  1  6  3  4  5  4  8  2 10  8 10  9  7  7  6  1  7  5  8  6  5  8\n",
      "  1  4  9  8 10 10  8  4  3  5  2  6  3  3  2  7  4  3  4  1  7  6  4  1\n",
      "  9  6  5  4  8  7  5  7  8 10  2  5  5  8  5  7  6  6  9  4  1  2  5  4\n",
      "  9  6  6  8  9  3  8 10  7  9  7  6  9]\n",
      "Predictions: [ 9. 10. 10. 10.  5.  7.  3.  8.  8.  6.  8.  7.  7. 10.  5.  5.  7.  7.\n",
      "  6.  8. 10.  5.  5.  8.  6.  7.  8.  5. 10.  7.  6.  6.  8.  5.  9. 10.\n",
      " 10.  7.  7.  8.  8.  7.  8.  5.  6.  8.  5.  5.  7.  9. 10.  6.  6.  5.\n",
      " 10. 10.  6.  9.  6.  4.  4.  7.  4.  5.  4. 10.  4.  6.  5.  6.  5.  5.\n",
      "  7.  5.  5.  7.  7.  5. 10.  9. 10. 10.  8.  7.  8.  5.  8.  6.  6.  7.\n",
      "  5. 10.  5.  8.  9.  8. 10.  8.  6.  5.  7. 10.  6.  6. 10. 10.  6.  7.\n",
      "  9.  8.  8.  5.  2.  5.  5. 10.  7.  3.  6.  5.  5.  7.  6.  9.  8. 10.\n",
      "  7.  8.  5. 10.  6.  6.  6.  6.  6.  4. 10.  5.  9.  7.  7.  5.  7.  7.\n",
      "  8.  6. 10.  7.  7.  6.  7. 10.  8.  7.  8.  8. 10. 10.  6. 10.  7.  7.\n",
      "  7.  5.  7.  5.  8.  4.  9. 10.  6.  5.  5.  5.  8. 10.  6.  8.  8. 10.\n",
      " 10.  9.  6.  8.  8.  7.  8.  6.  5.  8.  6. 10.  5.  4.  7.  9.  6. 10.\n",
      "  8.  7.  5.  8.  8.  8. 10.  4.  9.  8.  8. 10.  8.  8. 10.  7.  6.  6.\n",
      "  7.  7.  7.  9.  5.  8.  8.  8.  8.  5.  5. 10. 10.  7.  8.  8.  7.  3.\n",
      "  5.  6.  7.  7. 10.  5.  5.  5. 10.  9.  7.  6. 10.  7.  7.  5.  8. 10.\n",
      "  8. 10.  7. 10.  7.  6.  7.  5.  4.  8.  8.  8.  7.  8. 10.  4. 10.  8.\n",
      "  5. 10.  7.  5.  5.  8.  6. 10. 10.  4.  7. 10.  7.  7.  8.  6.  7.  7.\n",
      "  9. 10.  6.  8.  5.  6. 10. 10. 10.  6. 10.  5.  5.  6.  6.  7.  6. 10.\n",
      "  5.  7.  9. 10.  6.  5.  9.  6. 10.  8.  4.  5.  8.  8.  9.  5.  9.  7.\n",
      "  5.  8.  8.  5.  4.  5.  4.  8.  5.  6. 10.  6.  5.  5.  8.  3.  8.  5.\n",
      "  7.  8.  8.  5.  7.  5.  8.  5.  7.  6.  6.  5.  5. 10. 10.  9.  7.  6.\n",
      "  5.  7.  8. 10.  8.  5.  7.  7.  7.  4.  5. 10.  5.  7.  5.  6.  7.  9.\n",
      "  6. 10.  8.  6.  5.  6.  8.  5.  9.  7. 10. 10.  8.  5.  6.  8.  4.  4.\n",
      "  8.  2. 10.  7.  8.  6.  7. 10.  5.  5.  5.  7.  6. 10.  5.  7.  8.  5.\n",
      "  7.  4.  6.  7.  8. 10.  7.  8.  7.  9.  8.  8. 10.  5.  8.  5.  8. 10.\n",
      "  4.  8.  5.  5.  5.  8.  3.  7. 10. 10.  8. 10.  8.  7.  7.  7.  7.  9.\n",
      "  4.  8.  8.  6.  6.  6.  7.  7.  4. 10.  7.  7.  7. 10.  8. 10.  5.  6.\n",
      "  4. 10.  6.  7.  4.  5.  9. 10.  8.  6.  5.  8.  5.  8.  7.  8.  7.  7.\n",
      "  9.  3. 10.  7. 10.  7.  7.]\n",
      "Cleveland-McGill MLAE: 8.0533\n",
      "Per-Instance MLAE: 0.8373\n"
     ]
    }
   ],
   "source": [
    "# Filter data for GPT-4o\n",
    "gpt4o_df = df[df['model_name'] == 'gpt4o']\n",
    "\n",
    "# List unique predicted values\n",
    "unique_predictions = gpt4o_df['cleaned_answers'].unique()\n",
    "print(\"Unique Predicted Values for GPT-4o:\")\n",
    "print(unique_predictions)\n",
    "\n",
    "# Example Calculation for GPT-4o\n",
    "if not gpt4o_df.empty:\n",
    "    example_y_test = gpt4o_df['ground_truth'].values[:1000]\n",
    "    example_y_pred = gpt4o_df['cleaned_answers'].values[:1000]\n",
    "\n",
    "    mlae_Cleveland_McGill = Cleveland_McGill(example_y_pred, example_y_test)\n",
    "    mlae_per_instance = MLAE_per_instance(example_y_pred, example_y_test)\n",
    "\n",
    "    print(\"\\nExample MLAE Calculation for GPT-4o (First 5 Rows):\")\n",
    "    print(f\"Ground Truth: {example_y_test}\")\n",
    "    print(f\"Predictions: {example_y_pred}\")\n",
    "    print(f\"Cleveland-McGill MLAE: {mlae_Cleveland_McGill:.4f}\")\n",
    "    print(f\"Per-Instance MLAE: {mlae_per_instance:.4f}\")\n",
    "else:\n",
    "    print(\"\\nNo data found for GPT-4o.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Llama's mlae caculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Predicted Values for LLaMA:\n",
      "[  4.   5.   3.  10.   6.  15.   7. 100.   2.   8.   9.  20.  52.  36.\n",
      "  50.   1. 145.  35.  40.  30.  13. 140.  24. 152.  55.  90.  45. 300.\n",
      "  16.]\n",
      "\n",
      "Example MLAE Calculation for LLaMA (First 5 Rows):\n",
      "Predictions: [  4.   5.   5.   3.  10.   6.   4.  15.   6.   6.   5.   7.   6.   6.\n",
      "  10.   4.   5.   6.   6.   7.   5.   5.   6.   6.  10.   7.   4.   5.\n",
      " 100.   4.   2.   6.   4.   6.   6.   3.   4.   4.   6.   4.   6.   4.\n",
      "   3.   7.   7.   7.   4.   4.   7.   7.  10.   7.   6.   6.   5.   7.\n",
      "   7.   5.   6.   3. 100.  10.   8.   6.   6.   4.   7.   7.   5.   9.\n",
      "   7.   6.   6.   4.   4.  20.   6.   6.   3.   3.   3.   5.   5.  52.\n",
      "  36.   4.   3.   5.   6.   6.   6.   3.   6.   6.   4.  10.   5.  50.\n",
      "   4.   6.  10.   6.   5.   7.   5.   6.   6.   7.   5.   3.   3.   6.\n",
      "   5.   3.   7.   4.   2.   5.   3.   5.  10.   6.   5.   5.   4.   6.\n",
      "   7.   7.   1.  10.   5.   6.   6.   3.   5.   2.   3.   4.   5.   3.\n",
      "   5.   6.   6.   3.   4.   4.   6.   6.   5.   4.   5.   2.   4.   4.\n",
      "   5.   6.   3.   6.   4.   4.   4. 145.   6.   3.  10.   4.   5.   7.\n",
      "   6.   4.   3.   5.   7.   6.   5.   5.   6.   5.   6.   6.   6.   6.\n",
      "   4.   3.   3.   7.   7.   5.   5.   4.   7.   5.  35.   6.   7.  10.\n",
      "   5.   7.   4.   6.   6.   5.   6.   5.   3.   5.   4.   4.   5.   5.\n",
      "   6.   7.   7.  10.   7.   5.  40.   5.   6.   5.  30.   6.   7.  10.\n",
      "   6.   4.   3.   6.   5.   4.   6.   3.   5.   4.   5.   5.   7.   6.\n",
      "   4.   5.   6.   4.   3.   5.   7.   5.   3.   5.   7.   7.   3.   5.\n",
      "   7.   3.   6.  10.   5.   5.   3.   3.   9.   6.   7.   3.   6.   7.\n",
      "   6.   4.   6.   7.   7.   9.   8.   3.   5.   3.   5.   6.   7.   5.\n",
      "   6.  13.   6.   8.   5.   3.   6.  10.   6.  10. 140.   6.   5.   4.\n",
      "   6.   3.   4.   6.   6.   4.   4.   6.   8.   3.   5.   5.   7.   3.\n",
      "   4.   4.   6.   6.   6.   6.   5.  10.   5.   3.   7.   6.   4.   4.\n",
      "   5.   4.   6.   5.   7.   5.   7.   7.   5.   5.   4.   6.   6.   4.\n",
      "   7.   7.   6.   7.   5.   4.   6.   6.   5.   3.   6.   4.   4.   7.\n",
      "   9.   4.   6.   7.   5.   6.   5.   5.   4.   6.   6.   7.  24.   4.\n",
      "   4.   6.   6.   5.   6.   6.   5.   6.   5.  10.   3.   6.   5.   5.\n",
      "   7. 152.  36.  30.   8.   5.   3.   5.   5.   5.   6.   5.   6.   6.\n",
      "   5.   6.   4.   8.   9.  10.   7.   6.   6.   8.   6.   5.   5.   6.\n",
      "  10.   5.   6.   5.   6.   6.   6.   7.   5.   6.  55.   6.   7.   5.\n",
      "   6.   5.   7.   6.   6.   4.   6.   6.   4.   6.   5.   6.  90.   3.\n",
      "  10.   5.   4.   6.   6.   7.   3.   6.  45.   4.   3.   7. 300.   4.\n",
      "   7.   4.   5.   9.   4.   5. 100.   6.   6.   5.   7.  10.   4.   5.\n",
      "   3.   5.   6.   6.   6.   7.   6.   5.   4.  40.   7.  20.   5.  10.\n",
      "   6.   5.   6.   7.   5.   5.  16.   6.  10.   7.   5.   6.  35.   7.\n",
      "  10.   8.   6.   7.]\n",
      "Cleveland-McGill MLAE: 9.1475\n",
      "Per-Instance MLAE: 1.1656\n"
     ]
    }
   ],
   "source": [
    "# Filter data for LLaMA\n",
    "llama_df = df[df['model_name'] == 'LLaMA']\n",
    "\n",
    "# List unique predicted values\n",
    "unique_predictions_llama = llama_df['cleaned_answers'].unique()\n",
    "print(\"Unique Predicted Values for LLaMA:\")\n",
    "print(unique_predictions_llama)\n",
    "\n",
    "# Example Calculation for LLaMA\n",
    "if not llama_df.empty:\n",
    "    example_y_test = llama_df['ground_truth'].values[:1000]\n",
    "    example_y_pred = llama_df['cleaned_answers'].values[:1000]\n",
    "\n",
    "    mlae_Cleveland_McGill = Cleveland_McGill(example_y_pred, example_y_test)\n",
    "    mlae_per_instance = MLAE_per_instance(example_y_pred, example_y_test)\n",
    "\n",
    "    print(\"\\nExample MLAE Calculation for LLaMA (First 5 Rows):\")\n",
    "    #print(f\"Ground Truth: {example_y_test}\")\n",
    "    print(f\"Predictions: {example_y_pred}\")\n",
    "    print(f\"Cleveland-McGill MLAE: {mlae_Cleveland_McGill:.4f}\")\n",
    "    print(f\"Per-Instance MLAE: {mlae_per_instance:.4f}\")\n",
    "else:\n",
    "    print(\"\\nNo data found for LLaMA.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Predicted Values for custom LLaMA:\n",
      "[ 9. 10.  3.  2.  7.  4.  1.  6.  5.  8.]\n",
      "\n",
      "Example MLAE Calculation for LLaMA (First 5 Rows):\n",
      "Predictions: [ 9. 10.  3.  3. 10.  3.  2.  7.  4.  1.  2.  9.  9.  6.  1.  4.  4.  9.\n",
      "  6.  5.  1. 10. 10.  2.  2.  5.  1.  3.  6.  4.  9.  1.  6.  8.  1.  3.\n",
      "  3.  5. 10.  1.  7.  7.  4.  3.  2. 10.  6.  3. 10.  5.  5.  6.  9.  7.\n",
      "  3.  4.  1.  3.  2.  3.  5. 10.  6.  6.  2.  4.  6. 10.  5. 10.  1.  7.\n",
      "  9. 10.  9.  3.  5.  6.  3.  5.  3. 10. 10.  9.  6.  1.  4.  5.  6.  3.\n",
      "  3.  6.  1.  9.  3.  8.  4.  7. 10.  8.  8.  5.  5.  6.  7.  5.  4.  2.\n",
      "  9.  5.  7. 10.  1.  5.  5.  8.  2.  7. 10.  4.  8.  2. 10. 10. 10.  1.\n",
      "  5.  3.  6. 10.  9.  2.  2.  9.  7.  1.  9.  9.  9.  1.  3.  3.  1.  9.\n",
      "  2.  6.  9.  2.  3.  2.  1.  6.  4.  9.  1.  9.  5.  7.  8.  3.  7.  2.\n",
      "  7.  5.  2.  5. 10.  8. 10.  9.  7.  9.  6.  5.  1.  7.  6.  3.  2.  1.\n",
      "  6.  9.  3.  4.  9.  4.  5.  9.  4.  2.  3.  7.  6.  6.  9. 10. 10. 10.\n",
      "  6.  2.  1.  3.  1.  8. 10.  1.  2.  9.  9.  9. 10.  3.  6.  9. 10.  6.\n",
      "  5.  6. 10.  3.  1.  8.  7.  7.  5.  9.  4.  4.  8.  3.  8.  2.  2.  2.\n",
      "  2.  7.  9.  5.  2.  8.  3.  4.  9.  1.  6.  5.  6.  1.  9. 10.  6.  7.\n",
      "  4.  6.  3.  4.  9.  1.  4. 10.  9.  9. 10.  9.  9. 10.  3. 10.  1.  6.\n",
      "  3. 10.  3.  5.  4.  8.  3.  2.  8.  1.  8.  7.  4.  6.  5. 10.  7. 10.\n",
      "  9.  7.  4.  5.  3.  6.  9.  9.  4. 10.  6.  5. 10.  6.  3.  8.  7. 10.\n",
      "  3.  5.  5.  8.  5.  7.  9.  6.  5.  5.  3.  7.  7. 10.  6. 10. 10.  9.\n",
      "  4.  4.  5.  6.  5.  5.  5.  6.  9.  2.  1.  4. 10. 10.  5.  6.  5.  8.\n",
      "  6.  3.  3.  8.  7.  3.  2.  8.  6.  9.  8. 10. 10.  2.  1.  2.  1.  1.\n",
      "  7.  1.  2.  6.  9.  2.  2.  7.  3.  2.  9.  7. 10. 10.  6.  9.  2.  9.\n",
      "  3.  1.  9.  2.  4.  7.  6. 10.  5.  7.  1.  3.  6.  6.  2.  8.  7.  7.\n",
      "  6.  8.  5.  1.  7.  9. 10.  1.  9.  6.  4. 10.  5.  6.  7.  5.  2.  6.\n",
      "  5.  3.  6.  1.  3.  8.  6.  8.  6.  1.  6.  1.  6.  1.  6.  1.  8.  4.\n",
      "  1.  7.  6.  3.  1.  1.  3.  9.  5.  6. 10.  2. 10.  2.  8.  5.  3. 10.\n",
      "  3.  4.  3. 10.  2.  5. 10.  5.  3.  7.  1.  7.  8. 10.  3. 10.  1.  2.\n",
      "  1.  1.  6.  1.  6.  9.  4.  2.  2.  3.  2.  6. 10.  1.  1.  5.  9.  5.\n",
      "  3.  1. 10.  2.  7. 10.  3. 10. 10.]\n",
      "Cleveland-McGill MLAE: 8.3361\n",
      "Per-Instance MLAE: 1.1383\n"
     ]
    }
   ],
   "source": [
    "# Filter data for LLaMA\n",
    "llama_df = df[df['model_name'] == 'CustomLLaMA']\n",
    "\n",
    "# List unique predicted values\n",
    "unique_predictions_llama = llama_df['cleaned_answers'].unique()\n",
    "print(\"Unique Predicted Values for custom LLaMA:\")\n",
    "print(unique_predictions_llama)\n",
    "\n",
    "# Example Calculation for LLaMA\n",
    "if not llama_df.empty:\n",
    "    example_y_test = llama_df['ground_truth'].values[:1000]\n",
    "    example_y_pred = llama_df['cleaned_answers'].values[:1000]\n",
    "\n",
    "    mlae_Cleveland_McGill = Cleveland_McGill(example_y_pred, example_y_test)\n",
    "    mlae_per_instance = MLAE_per_instance(example_y_pred, example_y_test)\n",
    "\n",
    "    print(\"\\nExample MLAE Calculation for LLaMA (First 5 Rows):\")\n",
    "    #print(f\"Ground Truth: {example_y_test}\")\n",
    "    print(f\"Predictions: {example_y_pred}\")\n",
    "    print(f\"Cleveland-McGill MLAE: {mlae_Cleveland_McGill:.4f}\")\n",
    "    print(f\"Per-Instance MLAE: {mlae_per_instance:.4f}\")\n",
    "else:\n",
    "    print(\"\\nNo data found for LLaMA.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sbatch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
